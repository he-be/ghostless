# 開発日記: Project Ghostless (Simulacra) - 2026/01/11 ~ 01/12

今週末は「Ghostless」プロジェクト（3teneアバターの完全外部制御化）において、極めて重要な進展があった。特に後半の「顔制御」に関するピボットは、プロジェクトの方向性を決定づけるものとなった。

## 1. 動画合成パイプラインの確立 (1/11)
プロジェクトの初期段階として、VTuber映像とスライド資料を合成するパイプライン（`compositor.py`）の整備を行った。
当初はMoviePyを使用していたが、パフォーマンスと画質の問題からFFmpegネイティブ処理へ移行。これにより、FullHD解像度での正確なコンポジットが可能となり、今後の動画生成の基盤が整った。

## 2. 3tene TCP制御の解析 (1/12 前半)
3teneの外部制御ポート（3910）のリバースエンジニアリングを実施。
- `simulacra_controller.py` を作成し、ボーンIDのスキャンを実行。
- Hips(0), Spine(7), Head(10) などの主要ボーンのマッピングを特定。
- これにより、Pythonスクリプトからアバターの身体動作（呼吸、揺れ）をプロシージャルに生成・送信することに成功した（Simulacra Body）。

## 3. BVHモーションの互換性課題
より複雑な動きを取り入れるため、BVHファイルの読み込み（`simulacra_player.py`）を試みたが、ファイル形式やボーン構造の差異により難航。
現状ではプロシージャルな動き（数式による制御）の方が軽量かつ安定しているため、一旦BVHの優先度を下げ、直接制御へリソースを集中することにした。

## 4. "不気味の谷" と Anime 2.5D への転換 (1/12 後半)
身体の制御はTCPで確立したが、「表情（Face）」の制御が課題として残った。3teneの仕様上、表情はWebカメラ入力（Face Tracking）に依存するため、以下の試行錯誤を行った。

### 失敗：リアル顔写真 + プロシージャル描画
当初、リアルな人物の顔写真ベースのアセットを作成し、Pythonで目や口を描画してフェイクWebカメラ映像として流し込む手法を試みた。
しかし、リアルな肌とシンプルな図形の組み合わせが強烈な「不気味の谷（Uncanny Valley）」現象を引き起こし、却下となった。

### 成功：Anime 2.5D Spoofer
方針を転換し、アニメ調の静止画アセット（正面、右向き、口開け）を生成。
- メッシュ変形などを使わず、パラパラ漫画のように画像を切り替える「2.5D的」アプローチを採用。
- 左向き画像は右向き画像をプログラムで反転させることで効率化。
- MediaPipeによる検証を行い、この簡易的なアニメ顔でも3teneが「顔」として認識・追跡可能であることを実証した。

## 5. 仮想カメラの直接制御 (Direct Virtual Camera)
OBSのウィンドウキャプチャを経由する方法では、OBSでの録画と競合する問題が発覚。
`pyvirtualcam` ライブラリを導入し、PythonからOSの仮想カメラドライバへ直接映像フレームを転送する仕組みを構築。
これにより、OBSを起動することなく、バックグラウンドでPythonスクリプトが「仮想の演者」として顔映像を供給し、同時に身体動作信号を送出し続ける完全な「Simulacra」システム（`simulacra_integrated.py`）が完成した。

---
**成果:**
- TCPによる身体制御
- Python生成アニメ映像による表情制御（Webカメラハック）
- OBSレスな配信システムの構築

**次なる展望:**
- LLMなど外部脳との接続による、自律的な演技制御の実装。
